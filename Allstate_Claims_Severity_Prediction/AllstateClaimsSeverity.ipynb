{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "**Module name**: readTrainingData \n\n**Parameters**: None\n\n**Description**: \nReads the train.csv and separates the categorical and continuous data.\nThis module also removes the target *loss* values from the training data which is required as an input during training the predictive model.\n\n**Return values**:\n\n - **categories**: The categorical values read from the data\n - **continuous**: The continuous data read from the data\n - **target**: The ***loss*** values extracted from data\n - **data**: A dictionary of ***id*** as keys and the rest of the row of data as values (not used anywhere, did just in case if required at any time)",
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import csv\ndef readTrainingData():\n    data = {}\n    colNames = []\n    categories = []\n    continuous = []\n    target = []\n    target1 = []\n    with open('../input/train.csv') as csvfile:\n        trainReader = csv.reader(csvfile, delimiter=',')\n        count = 0\n        for row in trainReader:\n            if count == 0:\n                colNames = row\n                count+=1\n            else:\n                key = int(row[0])\n                row.pop(0)\n                categories.append(row[0:116])\n                continuous1 = row[116:130]\n                target1.extend(row[130:131])\n                idxToBeDeleted = len(row) - 1\n                row.pop(idxToBeDeleted)\n                continuous1 = [ float(x) for x in continuous1 ]\n                continuous.append(continuous1)\n                data[key] = row\n        for item in target1:\n            target.append(float(item))\n    return data, categories,continuous,target",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Below cell is just used to call the ***readTrainingData*** module",
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data, categories,continuous,target = readTrainingData()\nprint (\"readTrainingData done\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Module name**: categoryEncoder\n\n**Parameters**: \n\n - **categories**: Categories values extracted during **readTrainingData**\n - **continuous**: Continuous values extracted during **readTrainingData**\n\n**Description**: \nThis is the most important module since it converts the training categorical data into continuous ones. This is how its done:\n\n - Every unique category in the training data, is assigned a unique ***label*** \n\n - Now this ***label*** is replaced in the place of categorical values in a 2D list called encodedCategories.\n\n - A dictionary of unique categories along with their labels is maintained to use during encoding of test data categories\n\nThe continuous and encoded categorical values are zipped together to resemble the training data\n\n**Return values**:\n\n - **encodedCategories**: The encoded categorical values\n - **uniqCatAndCounts**: A dictionary of categories and its labels required during test data categories encoding.\n ",
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def categoryEncoder(categories,continuous): \n    uniqCatAndCounts = {}\n    numRows = len(categories)\n    numCols = len(categories[0])\n    encodedCategories = [[0 for x in range(numCols)] for y in range(numRows)] \n    for i in range(numRows):\n        for j in range(numCols):\n            if categories[i][j] in uniqCatAndCounts:\n                uniqCatAndCounts[categories[i][j]] += 1\n            else:\n                uniqCatAndCounts[categories[i][j]] = 1\n    label = 1\n    for cat in uniqCatAndCounts:\n        uniqCatAndCounts[cat] = label\n        label += 1\n    for i in range(numRows):\n        for j in range(numCols):\n            if categories[i][j] in uniqCatAndCounts:\n                encodedCategories[i][j] = float(uniqCatAndCounts[categories[i][j]])\n        encodedCategories[i].extend(continuous[i])\n    return encodedCategories,uniqCatAndCounts\n\nencodedCategories,uniqCatAndCounts = categoryEncoder(categories,continuous)\nprint (\"categoryEncoder done\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Module name**: readTestData\n\n**Parameters**: None\n\n**Description**: Reads the test.csv and separates the categorical and continuous data.\nThis module separates the test ids which is needed in producing final predicted values.\n\n\n**Return values**:\n\n - **categories**: The categorical values read from the data\n - **continuous**: The continuous data read from the data\n - **testIds**: The ***id*** of each row in the test data\n - **data**: A dictionary of ***id*** as keys and the rest of the row of data as values (not used anywhere, did just in case if required at any time)\n ",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import csv\ndef readTestData():\n    data = {}\n    testIds = []\n    colNames = []\n    categories = []\n    continuous = []\n    count = 0\n    with open('../input/test.csv') as csvfile:\n        testReader = csv.reader(csvfile, delimiter=',')\n        for row in testReader:\n            if count == 0:\n                colNames = row\n                count+=1\n            else:\n                key = int(row[0])\n                testIds.append(int(row.pop(0)))\n                categories.append(row[0:116])\n                continuous1 = row[116:130]\n                continuous1 = [ float(x) for x in continuous1 ]\n                continuous.append(continuous1)\n                data[key] = row\n    return data, categories, continuous, testIds\n\ndataTest, categoriesTest, continuousTest, testIds = readTestData()\nprint(\"readTestData done\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Module name**: testCatEncoder\n\n**Parameters**: \n\n - **categoriesTest**: Categories values extracted during **readTestData**\n - **continuousTest**: Continuous values extracted during **readTestData**\n - **uniqCatAndCounts**: The categories and their labels read from **readTrainingData**\n\n**Description**: \nThis is another important module since it converts the test categorical data into continuous ones. This is how its done:\n\n - Every category in the test data, is replaced by the ***label*** read and stored in  ***uniqCatAndCounts*** during ***readTrainingData***.\n\n - If there is a category in the test data which was not in train data, that category is assigned a new label and is stored in ***uniqCatAndCounts*** \n\nThe continuous and encoded categorical values are zipped together to resemble the test data\n\n**Return values**:\n\n - **encodedCategoriesTest**: The encoded categorical values from test data\n - **uniqCatAndCounts**: An updated dictionary of categories and its labels",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def testCatEncoder(categoriesTest, uniqCatAndCounts, continuousTest):\n    #encodedCategoriesTest = categoriesTest\n    numRows = len(categoriesTest)\n    numCols = len(categoriesTest[0])\n    label = len(uniqCatAndCounts) + 1\n    encodedCategoriesTest = [[0 for x in range(numCols)] for y in range(numRows)] \n    for i in range(numRows):\n        for j in range(numCols):\n            if categoriesTest[i][j] in uniqCatAndCounts:\n                encodedCategoriesTest[i][j] = float(uniqCatAndCounts[categoriesTest[i][j]])\n            else:\n                #Should update uniqCatAndCounts with new key and new value\n                uniqCatAndCounts[categoriesTest[i][j]] = label\n                encodedCategoriesTest[i][j] = label\n                label += 1\n        encodedCategoriesTest[i].extend(continuousTest[i])\n    return uniqCatAndCounts, encodedCategoriesTest\n\nuniqCatAndCounts, encodedCategoriesTest = testCatEncoder(categoriesTest, uniqCatAndCounts, continuousTest)\nprint(\"testCatEncoder done\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Preparing model with required parameters\nimport numpy as np\nfrom xgboost import XGBRegressor\n\nseed = 0\nn_estimators = 1000\n\nbest_model = XGBRegressor(n_estimators=n_estimators,seed=seed)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "splitIdx = int(0.2*len(encodedCategories))\n\nfrom sklearn.metrics import mean_absolute_error\n\n#Split the data into 80 and 20 percent\nencodedCategories_X_train = encodedCategories[:-splitIdx]\nencodedCategories_X_test = encodedCategories[-splitIdx:]\n\n#Applying log transformation to reduce the bias of the target values\nlogTransformedLoss = list(np.log(target))\n\n# Split the targets into training/testing sets\ntarget_y_train = logTransformedLoss[:-splitIdx]\ntarget_y_test = logTransformedLoss[-splitIdx:]\n\nfit2 = best_model.fit(encodedCategories_X_train, target_y_train)\n\n#fetch mean absolute error required for measuring the accuracy in the current contest\nmean_absolute_error(np.exp(fit2.predict(encodedCategories_X_test)), np.exp(target_y_test))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "testPredictions = np.exp(fit2.predict(encodedCategoriesTest))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Write the predicted values into csv file along with their ids\nimport csv\ntestIdsWithPredictions = zip(testIds, testPredictions)\nwith open('result.csv', 'w') as out:\n    csv_out=csv.writer(out)\n    csv_out.writerow(['id','loss'])\n    for row in testIdsWithPredictions:\n        csv_out.writerow(row)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}